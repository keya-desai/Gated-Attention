{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB Review Classifier using LSTM\n",
    "\n",
    "GA-Net code without Auxilliary Network  \n",
    "Backbone network = LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "D0T3nxESJstz",
    "outputId": "7341ce37-5134-467c-9d54-16650d84097e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip3 install torchtext==0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a9sHZi8rIXBC"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pdb\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions\n",
    "import torch.optim as optim\n",
    "from torch import nn \n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import Vectors, GloVe\n",
    "\n",
    "# from models.LSTM import LSTMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6CtSKjSRaQdd"
   },
   "outputs": [],
   "source": [
    "# model.py\n",
    "\n",
    "class GANet(torch.nn.Module):\n",
    "    def __init__(self, batch_size, num_classes, mlp_out_size, vocab_size, embedding_length, weights, aux_hidden_size = 100, backbone_hidden_size = 100, tau = 1, biDirectional_aux = False, biDirectional_backbone = False):\n",
    "        super(GANet, self).__init__() \n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        batch_size : Size of the batch which is same as the batch_size of the data returned by the TorchText BucketIterator\n",
    "        output_size : 6 = (For TREC dataset)\n",
    "        hidden_sie : Size of the hidden_state of the LSTM   (// Later BiLSTM)\n",
    "        vocab_size : Size of the vocabulary containing unique words\n",
    "        embedding_length : Embeddding dimension of GloVe word embeddings\n",
    "        weights : Pre-trained GloVe word_embeddings which we will use to create our word_embedding look-up table \n",
    "\n",
    "        --------\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.num_classes = num_classes\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_length = embedding_length\n",
    "        self.aux_hidden_size = aux_hidden_size\n",
    "        self.backbone_hidden_size = backbone_hidden_size \n",
    "        self.mlp_out_size = mlp_out_size\n",
    "        self.biDirectional_aux = biDirectional_aux\n",
    "        self.biDirectional_backbone = biDirectional_backbone\n",
    "        self.tau = tau\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_length)\n",
    "        self.word_embeddings.weights = nn.Parameter(weights, requires_grad=False)\n",
    "        \n",
    "        self.backbone = BackboneNet(self.batch_size, self.backbone_hidden_size, self.embedding_length, self.biDirectional_backbone)\n",
    "        \n",
    "        if(self.biDirectional_backbone):\n",
    "            self.mlp = MLP(self.backbone_hidden_size * 2, self.mlp_out_size)\n",
    "            self.FF = nn.Linear(self.backbone_hidden_size * 2,num_classes)\n",
    "        else:\n",
    "            self.mlp = MLP(self.backbone_hidden_size, self.mlp_out_size)\n",
    "            self.FF = nn.Linear(self.backbone_hidden_size,self.num_classes)\n",
    "\n",
    "    def forward(self,input_sequence, is_train = True):\n",
    "        input_ = self.word_embeddings(input_sequence)\n",
    "        out_lstm, final_hidden_state = self.backbone(input_)\n",
    "        ff_output = self.FF(final_hidden_state[-1])\n",
    "#         print(\"FF out size: \", ff_output.shape)\n",
    "        predictions = torch.softmax(ff_output, dim = -1)\n",
    "        return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YT9xWP_MAVmq"
   },
   "outputs": [],
   "source": [
    "class BackboneNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        batch_size : Size of the batch which is same as the batch_size of the data returned by the TorchText BucketIterator\n",
    "        backbone_hidden_size : Size of the hidden_state of the LSTM   (* Later BiLSTM, check dims for BiLSTM *)\n",
    "        embedding_length : Embeddding dimension of GloVe word embeddings\n",
    "        --------\n",
    "    \"\"\"\n",
    "    def __init__(self, batch_size, backbone_hidden_size, embedding_length, biDirectional = False, num_layers = 2):\n",
    "\n",
    "        super(BackboneNet, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_size = backbone_hidden_size\n",
    "        self.embedding_length = embedding_length\n",
    "        self.biDirectional\t= biDirectional\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.backbone_lstm = nn.LSTM(self.embedding_length, self.hidden_size, bidirectional = self.biDirectional, batch_first = True, num_layers = self.num_layers)   # Dropout  \n",
    "\n",
    "    def forward(self, input_sequence, batch_size=None):\n",
    "        out_lstm, (final_hidden_state, final_cell_state) = self.backbone_lstm(input_sequence)   # ouput dim: ( batch_size x seq_len x hidden_size )\n",
    "        return out_lstm, final_hidden_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x_eU0HR-j8lW"
   },
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.ff_1 = nn.Linear(self.input_dim, self.output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.ff_2 = nn.Linear(self.output_dim,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self,x):\n",
    "        out_1 = self.ff_1(x)\n",
    "        out_relu = self.relu(out_1)\n",
    "        out_2 = self.ff_2(out_relu)\n",
    "        out_sigmoid = self.sigmoid(out_2)\n",
    "\n",
    "        return out_sigmoid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Swz_WT2mS3zq"
   },
   "outputs": [],
   "source": [
    "def clip_gradient(model, clip_value):\n",
    "    params = list(filter(lambda p: p.grad is not None, model.parameters()))\n",
    "    for p in params:\n",
    "        p.grad.data.clamp_(-clip_value, clip_value)\n",
    "    \n",
    "def train_model(model, optim, train_iter, epoch, batch_size):\n",
    "    total_epoch_loss = 0\n",
    "    total_epoch_acc = 0\n",
    "#     optim = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "    steps = 0\n",
    "    model.train()\n",
    "    for idx, batch in enumerate(train_iter):\n",
    "        text = batch.text[0]\n",
    "        target = batch.label\n",
    "        target = torch.autograd.Variable(target).long()\n",
    "        if torch.cuda.is_available():\n",
    "            text = text.cuda()\n",
    "            target = target.cuda()\n",
    "        if (text.size()[0] is not batch_size):# One of the batch returned by BucketIterator has length different than 32.\n",
    "            continue\n",
    "        optim.zero_grad()\n",
    "        prediction = model(text, is_train = True)\n",
    "#         print(\"prediction = \", prediction.shape)\n",
    "#         print(\"target = \", target.shape)\n",
    "#         print(\"prediction = \", prediction)\n",
    "#         print(\"target = \", target)\n",
    "\n",
    "\n",
    "        # Defualt - Cross entropy loss funtion\n",
    "        loss = loss_fn(prediction, target)\n",
    "        \n",
    "        # print(\"loss = \", loss)\n",
    "        \n",
    "        num_corrects = (torch.max(prediction, 1)[1].view(target.size()).data == target.data).float().sum()\n",
    "        acc = 100.0 * num_corrects/len(batch)\n",
    "        loss.backward()\n",
    "        clip_gradient(model, 1e-1)\n",
    "        optim.step()\n",
    "        steps += 1\n",
    "        \n",
    "        total_epoch_loss += loss.item()\n",
    "        total_epoch_acc += acc.item()\n",
    "\n",
    "        \n",
    "    return total_epoch_loss/len(train_iter), total_epoch_acc/len(train_iter)\n",
    "\n",
    "def eval_model(model, val_iter):\n",
    "    total_epoch_loss = 0\n",
    "    total_epoch_acc = 0\n",
    "    total_attention =  0\n",
    "    total_samples = 0 \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(val_iter):\n",
    "            text = batch.text[0]\n",
    "            if (text.size()[0] is not 32):\n",
    "                continue\n",
    "            target = batch.label\n",
    "            target = torch.autograd.Variable(target).long()\n",
    "            if torch.cuda.is_available():\n",
    "                text = text.cuda()\n",
    "                target = target.cuda()\n",
    "            prediction = model(text, is_train = False)\n",
    "            # Sanity check\n",
    "            # print(\"Test Prediction: \", prediction)\n",
    "\n",
    "            # Defualt - Cross entropy loss funtion\n",
    "            loss =  loss_fn(prediction, target)\n",
    "            \n",
    "            if math.isnan(loss.item()):\n",
    "                print(prediction, target)\n",
    "            \n",
    "            num_corrects = (torch.max(prediction, 1)[1].view(target.size()).data == target.data).sum()\n",
    "            acc = 100.0 * num_corrects/len(batch)\n",
    "            total_epoch_loss += loss.item()\n",
    "            total_epoch_acc += acc.item()\n",
    "            \n",
    "    return total_epoch_loss/len(val_iter), total_epoch_acc/len(val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vAjlrmkGSEQQ"
   },
   "outputs": [],
   "source": [
    "# data.py\n",
    "def load_IMDB_data(batch_size= 32, embedding_length = 100):\n",
    "    # set up fields\n",
    "    tokenize = lambda x: x.split()\n",
    "    TEXT = data.Field(sequential=True, tokenize=tokenize, lower=True, include_lengths=True, batch_first=True, fix_length= 10)\n",
    "    # LABEL = data.LabelField()\n",
    "    LABEL = data.LabelField(dtype=torch.float)\n",
    "\n",
    "    # make splits for data\n",
    "    train, test = datasets.TREC.splits(TEXT, LABEL)\n",
    "    train, valid = train.split() \n",
    "    \n",
    "    # build the vocabulary\n",
    "    TEXT.build_vocab(train, vectors=GloVe(name='6B', dim=embedding_length))\n",
    "    LABEL.build_vocab(train)\n",
    "    print(LABEL.vocab.__dict__)\n",
    "\n",
    "    # make iterator for splits\n",
    "    train_iter, valid_iter, test_iter = data.BucketIterator.splits(\n",
    "      (train, valid, test), batch_size= batch_size, device=0)\n",
    "\n",
    "    word_embeddings = TEXT.vocab.vectors\n",
    "    vocab_size = len(TEXT.vocab)\n",
    "\n",
    "    return TEXT, vocab_size, word_embeddings, train_iter, valid_iter, test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "xHuvlEncW_tw",
    "outputId": "ea08c54e-f4c1-4785-cf86-c072a8dd620f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'freqs': Counter({'ENTY': 888, 'HUM': 876, 'DESC': 816, 'NUM': 604, 'LOC': 575, 'ABBR': 57}), 'itos': ['ENTY', 'HUM', 'DESC', 'NUM', 'LOC', 'ABBR'], 'unk_index': None, 'stoi': defaultdict(None, {'ENTY': 0, 'HUM': 1, 'DESC': 2, 'NUM': 3, 'LOC': 4, 'ABBR': 5}), 'vectors': None}\n"
     ]
    }
   ],
   "source": [
    "# main.py\n",
    "TEXT, vocab_size, word_embeddings, train_iter, valid_iter, test_iter = load_IMDB_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PImJSOJmzQgT"
   },
   "outputs": [],
   "source": [
    "# Over-writing the loss function to simple cross entropy loss\n",
    "loss_fn = F.cross_entropy\n",
    "\n",
    "learning_rate = 2e-5\n",
    "batch_size = 32\n",
    "output_size = 2\n",
    "hidden_size = 256\n",
    "embedding_length = 100\n",
    "num_classes = 2\n",
    "mlp_out_size = 32\n",
    "weights = word_embeddings\n",
    "aux_hidden_size = 100\n",
    "batch_hidden_size = 100\n",
    "tau = 1\n",
    "\n",
    "model = GANet(batch_size, num_classes, mlp_out_size, vocab_size, embedding_length, weights, biDirectional_backbone=False)\n",
    "optim = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 830
    },
    "colab_type": "code",
    "id": "EcU6SSW8bDln",
    "outputId": "49069342-b9dd-4d4c-d2f3-6509dd836057"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01\n",
      "*** Least validation loss\n",
      "Train Loss: 1.662, Train Acc: 34.24%\n",
      "Val Loss: 1.521777, Val Acc: 49.40%\n",
      "-------------\n",
      "Epoch: 02\n",
      "*** Least validation loss\n",
      "Train Loss: 1.473, Train Acc: 55.18%\n",
      "Val Loss: 1.443807, Val Acc: 55.05%\n",
      "-------------\n",
      "Epoch: 03\n",
      "*** Least validation loss\n",
      "Train Loss: 1.396, Train Acc: 62.81%\n",
      "Val Loss: 1.411567, Val Acc: 58.65%\n",
      "-------------\n",
      "Epoch: 04\n",
      "*** Least validation loss\n",
      "Train Loss: 1.344, Train Acc: 67.99%\n",
      "Val Loss: 1.332813, Val Acc: 67.07%\n",
      "-------------\n",
      "Epoch: 05\n",
      "*** Least validation loss\n",
      "Train Loss: 1.245, Train Acc: 77.99%\n",
      "Val Loss: 1.308926, Val Acc: 69.41%\n",
      "-------------\n",
      "Epoch: 06\n",
      "*** Least validation loss\n",
      "Train Loss: 1.219, Train Acc: 80.78%\n",
      "Val Loss: 1.284176, Val Acc: 72.24%\n",
      "-------------\n",
      "Epoch: 07\n",
      "*** Least validation loss\n",
      "Train Loss: 1.204, Train Acc: 82.34%\n",
      "Val Loss: 1.280423, Val Acc: 71.94%\n",
      "-------------\n",
      "Epoch: 08\n",
      "*** Least validation loss\n",
      "Train Loss: 1.184, Train Acc: 84.19%\n",
      "Val Loss: 1.271446, Val Acc: 72.90%\n",
      "-------------\n",
      "Epoch: 09\n",
      "*** Least validation loss\n",
      "Train Loss: 1.177, Train Acc: 85.00%\n",
      "Val Loss: 1.259826, Val Acc: 74.28%\n",
      "-------------\n",
      "Epoch: 10\n",
      "*** Least validation loss\n",
      "Train Loss: 1.172, Train Acc: 85.34%\n",
      "Val Loss: 1.251865, Val Acc: 75.48%\n",
      "-------------\n",
      "Epoch: 11\n",
      "*** Least validation loss\n",
      "Train Loss: 1.153, Train Acc: 87.34%\n",
      "Val Loss: 1.235647, Val Acc: 76.98%\n",
      "-------------\n",
      "Epoch: 12\n",
      "Train Loss: 1.144, Train Acc: 88.20%\n",
      "Val Loss: 1.241827, Val Acc: 75.84%\n",
      "-------------\n",
      "Epoch: 13\n",
      "Train Loss: 1.136, Train Acc: 89.11%\n",
      "Val Loss: 1.235829, Val Acc: 76.74%\n",
      "-------------\n",
      "Epoch: 14\n",
      "Train Loss: 1.132, Train Acc: 89.43%\n",
      "Val Loss: 1.235735, Val Acc: 76.86%\n",
      "-------------\n",
      "Epoch: 15\n",
      "Train Loss: 1.130, Train Acc: 89.77%\n",
      "Val Loss: 1.245841, Val Acc: 75.84%\n",
      "-------------\n",
      "Epoch: 16\n",
      "Train Loss: 1.123, Train Acc: 90.42%\n",
      "Val Loss: 1.236720, Val Acc: 76.56%\n",
      "-------------\n",
      "Epoch: 17\n",
      "Train Loss: 1.117, Train Acc: 90.99%\n",
      "Val Loss: 1.236842, Val Acc: 76.50%\n",
      "-------------\n",
      "Epoch: 18\n",
      "Train Loss: 1.114, Train Acc: 91.20%\n",
      "Val Loss: 1.236175, Val Acc: 76.62%\n",
      "-------------\n",
      "Epoch: 19\n",
      "*** Least validation loss\n",
      "Train Loss: 1.109, Train Acc: 91.80%\n",
      "Val Loss: 1.231912, Val Acc: 76.98%\n",
      "-------------\n",
      "Epoch: 20\n",
      "*** Least validation loss\n",
      "Train Loss: 1.107, Train Acc: 92.01%\n",
      "Val Loss: 1.230793, Val Acc: 77.22%\n",
      "-------------\n",
      "Epoch: 21\n",
      "*** Least validation loss\n",
      "Train Loss: 1.104, Train Acc: 92.27%\n",
      "Val Loss: 1.226525, Val Acc: 77.64%\n",
      "-------------\n",
      "Epoch: 22\n",
      "Train Loss: 1.105, Train Acc: 92.14%\n",
      "Val Loss: 1.232260, Val Acc: 76.98%\n",
      "-------------\n",
      "Epoch: 23\n",
      "Train Loss: 1.106, Train Acc: 92.06%\n",
      "Val Loss: 1.227947, Val Acc: 77.58%\n",
      "-------------\n",
      "Epoch: 24\n",
      "Train Loss: 1.110, Train Acc: 91.64%\n",
      "Val Loss: 1.228443, Val Acc: 77.64%\n",
      "-------------\n",
      "Epoch: 25\n",
      "Train Loss: 1.105, Train Acc: 92.11%\n",
      "Val Loss: 1.228285, Val Acc: 77.40%\n",
      "-------------\n",
      "Epoch: 26\n",
      "Train Loss: 1.104, Train Acc: 92.21%\n",
      "Val Loss: 1.226767, Val Acc: 77.70%\n",
      "-------------\n",
      "Epoch: 27\n",
      "Train Loss: 1.103, Train Acc: 92.40%\n",
      "Val Loss: 1.230405, Val Acc: 77.46%\n",
      "-------------\n",
      "Epoch: 28\n",
      "Train Loss: 1.101, Train Acc: 92.60%\n",
      "Val Loss: 1.228685, Val Acc: 77.40%\n",
      "-------------\n",
      "Epoch: 29\n",
      "Train Loss: 1.096, Train Acc: 93.02%\n",
      "Val Loss: 1.227215, Val Acc: 77.58%\n",
      "-------------\n",
      "Epoch: 30\n",
      "Train Loss: 1.095, Train Acc: 93.20%\n",
      "Val Loss: 1.233009, Val Acc: 77.16%\n",
      "-------------\n",
      "Epoch: 31\n",
      "Train Loss: 1.092, Train Acc: 93.49%\n",
      "Val Loss: 1.227196, Val Acc: 77.82%\n",
      "-------------\n",
      "Epoch: 32\n",
      "*** Least validation loss\n",
      "Train Loss: 1.094, Train Acc: 93.26%\n",
      "Val Loss: 1.216147, Val Acc: 78.73%\n",
      "-------------\n",
      "Epoch: 33\n",
      "Train Loss: 1.091, Train Acc: 93.65%\n",
      "Val Loss: 1.220208, Val Acc: 78.31%\n",
      "-------------\n",
      "Epoch: 34\n",
      "Train Loss: 1.088, Train Acc: 93.83%\n",
      "Val Loss: 1.217898, Val Acc: 78.37%\n",
      "-------------\n",
      "Epoch: 35\n",
      "Train Loss: 1.086, Train Acc: 94.01%\n",
      "Val Loss: 1.224203, Val Acc: 77.82%\n",
      "-------------\n",
      "Epoch: 36\n",
      "Train Loss: 1.086, Train Acc: 94.04%\n",
      "Val Loss: 1.220966, Val Acc: 78.43%\n",
      "-------------\n",
      "Epoch: 37\n",
      "Train Loss: 1.086, Train Acc: 94.01%\n",
      "Val Loss: 1.219741, Val Acc: 78.37%\n",
      "-------------\n",
      "Epoch: 38\n",
      "Train Loss: 1.099, Train Acc: 92.73%\n",
      "Val Loss: 1.236370, Val Acc: 76.62%\n",
      "-------------\n",
      "Epoch: 39\n",
      "Train Loss: 1.102, Train Acc: 92.45%\n",
      "Val Loss: 1.241997, Val Acc: 75.96%\n",
      "-------------\n",
      "Epoch: 40\n",
      "Train Loss: 1.099, Train Acc: 92.76%\n",
      "Val Loss: 1.225452, Val Acc: 77.70%\n",
      "-------------\n",
      "Epoch: 41\n",
      "Train Loss: 1.093, Train Acc: 93.39%\n",
      "Val Loss: 1.223928, Val Acc: 77.82%\n",
      "-------------\n",
      "Epoch: 42\n",
      "Train Loss: 1.094, Train Acc: 93.20%\n",
      "Val Loss: 1.227251, Val Acc: 77.64%\n",
      "-------------\n",
      "Epoch: 43\n",
      "Train Loss: 1.088, Train Acc: 93.93%\n",
      "Val Loss: 1.225823, Val Acc: 77.76%\n",
      "-------------\n",
      "Epoch: 44\n",
      "Train Loss: 1.082, Train Acc: 94.51%\n",
      "Val Loss: 1.225068, Val Acc: 77.58%\n",
      "-------------\n",
      "Epoch: 45\n",
      "Train Loss: 1.082, Train Acc: 94.43%\n",
      "Val Loss: 1.225730, Val Acc: 77.58%\n",
      "-------------\n",
      "Epoch: 46\n",
      "Train Loss: 1.081, Train Acc: 94.56%\n",
      "Val Loss: 1.217396, Val Acc: 78.73%\n",
      "-------------\n",
      "Epoch: 47\n",
      "Train Loss: 1.079, Train Acc: 94.71%\n",
      "Val Loss: 1.217679, Val Acc: 78.67%\n",
      "-------------\n",
      "Epoch: 48\n",
      "Train Loss: 1.083, Train Acc: 94.45%\n",
      "Val Loss: 1.217296, Val Acc: 78.49%\n",
      "-------------\n",
      "Epoch: 49\n",
      "Train Loss: 1.079, Train Acc: 94.77%\n",
      "Val Loss: 1.227648, Val Acc: 77.58%\n",
      "-------------\n",
      "Epoch: 50\n",
      "Train Loss: 1.080, Train Acc: 94.69%\n",
      "Val Loss: 1.218488, Val Acc: 78.37%\n",
      "-------------\n",
      "Epoch: 51\n",
      "Train Loss: 1.078, Train Acc: 94.90%\n",
      "Val Loss: 1.218295, Val Acc: 78.49%\n",
      "-------------\n",
      "Epoch: 52\n",
      "Train Loss: 1.077, Train Acc: 94.97%\n",
      "Val Loss: 1.218052, Val Acc: 78.31%\n",
      "-------------\n",
      "Epoch: 53\n",
      "Train Loss: 1.077, Train Acc: 95.00%\n",
      "Val Loss: 1.218093, Val Acc: 78.37%\n",
      "-------------\n",
      "Epoch: 54\n",
      "Train Loss: 1.076, Train Acc: 95.00%\n",
      "Val Loss: 1.216748, Val Acc: 78.67%\n",
      "-------------\n",
      "Epoch: 55\n",
      "Train Loss: 1.076, Train Acc: 95.08%\n",
      "Val Loss: 1.217535, Val Acc: 78.67%\n",
      "-------------\n",
      "Epoch: 56\n",
      "Train Loss: 1.075, Train Acc: 95.13%\n",
      "Val Loss: 1.220099, Val Acc: 78.37%\n",
      "-------------\n",
      "Epoch: 57\n",
      "*** Least validation loss\n",
      "Train Loss: 1.075, Train Acc: 95.13%\n",
      "Val Loss: 1.214769, Val Acc: 79.03%\n",
      "-------------\n",
      "Epoch: 58\n",
      "Train Loss: 1.075, Train Acc: 95.13%\n",
      "Val Loss: 1.216289, Val Acc: 78.79%\n",
      "-------------\n",
      "Epoch: 59\n",
      "Train Loss: 1.075, Train Acc: 95.16%\n",
      "Val Loss: 1.215711, Val Acc: 78.67%\n",
      "-------------\n",
      "Epoch: 60\n",
      "*** Least validation loss\n",
      "Train Loss: 1.075, Train Acc: 95.16%\n",
      "Val Loss: 1.213865, Val Acc: 79.09%\n",
      "-------------\n",
      "Epoch: 61\n",
      "Train Loss: 1.074, Train Acc: 95.23%\n",
      "Val Loss: 1.216549, Val Acc: 78.79%\n",
      "-------------\n",
      "Epoch: 62\n",
      "Train Loss: 1.075, Train Acc: 95.13%\n",
      "Val Loss: 1.216818, Val Acc: 78.85%\n",
      "-------------\n",
      "Epoch: 63\n",
      "Train Loss: 1.076, Train Acc: 95.03%\n",
      "Val Loss: 1.221732, Val Acc: 78.00%\n",
      "-------------\n",
      "Epoch: 64\n",
      "Train Loss: 1.078, Train Acc: 94.82%\n",
      "Val Loss: 1.220915, Val Acc: 78.12%\n",
      "-------------\n",
      "Epoch: 65\n",
      "Train Loss: 1.078, Train Acc: 94.87%\n",
      "Val Loss: 1.219955, Val Acc: 78.55%\n",
      "-------------\n",
      "Epoch: 66\n",
      "Train Loss: 1.076, Train Acc: 95.03%\n",
      "Val Loss: 1.216417, Val Acc: 78.79%\n",
      "-------------\n",
      "Epoch: 67\n",
      "Train Loss: 1.077, Train Acc: 94.95%\n",
      "Val Loss: 1.223847, Val Acc: 77.88%\n",
      "-------------\n",
      "Epoch: 68\n",
      "Train Loss: 1.076, Train Acc: 95.10%\n",
      "Val Loss: 1.215592, Val Acc: 78.79%\n",
      "-------------\n",
      "Epoch: 69\n",
      "Train Loss: 1.075, Train Acc: 95.16%\n",
      "Val Loss: 1.219611, Val Acc: 78.25%\n",
      "-------------\n",
      "Epoch: 70\n",
      "*** Least validation loss\n",
      "Train Loss: 1.074, Train Acc: 95.26%\n",
      "Val Loss: 1.211516, Val Acc: 79.15%\n",
      "-------------\n",
      "Epoch: 71\n",
      "*** Least validation loss\n",
      "Train Loss: 1.076, Train Acc: 95.05%\n",
      "Val Loss: 1.211091, Val Acc: 79.09%\n",
      "-------------\n",
      "Epoch: 72\n",
      "*** Least validation loss\n",
      "Train Loss: 1.080, Train Acc: 94.64%\n",
      "Val Loss: 1.208636, Val Acc: 79.39%\n",
      "-------------\n",
      "Epoch: 73\n",
      "Train Loss: 1.082, Train Acc: 94.48%\n",
      "Val Loss: 1.239141, Val Acc: 76.62%\n",
      "-------------\n",
      "Epoch: 74\n",
      "Train Loss: 1.076, Train Acc: 95.08%\n",
      "Val Loss: 1.224720, Val Acc: 77.70%\n",
      "-------------\n",
      "Epoch: 75\n",
      "Train Loss: 1.075, Train Acc: 95.21%\n",
      "Val Loss: 1.218403, Val Acc: 78.49%\n",
      "-------------\n",
      "Epoch: 76\n",
      "Train Loss: 1.074, Train Acc: 95.26%\n",
      "Val Loss: 1.216998, Val Acc: 78.61%\n",
      "-------------\n",
      "Epoch: 77\n",
      "Train Loss: 1.073, Train Acc: 95.36%\n",
      "Val Loss: 1.225727, Val Acc: 77.64%\n",
      "-------------\n",
      "Epoch: 78\n",
      "Train Loss: 1.072, Train Acc: 95.47%\n",
      "Val Loss: 1.213268, Val Acc: 79.21%\n",
      "-------------\n",
      "Epoch: 79\n",
      "Train Loss: 1.072, Train Acc: 95.44%\n",
      "Val Loss: 1.222423, Val Acc: 78.06%\n",
      "-------------\n",
      "Epoch: 80\n",
      "Train Loss: 1.071, Train Acc: 95.55%\n",
      "Val Loss: 1.214287, Val Acc: 78.85%\n",
      "-------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 81\n",
      "Train Loss: 1.071, Train Acc: 95.62%\n",
      "Val Loss: 1.208966, Val Acc: 79.27%\n",
      "-------------\n",
      "Epoch: 82\n",
      "*** Least validation loss\n",
      "Train Loss: 1.070, Train Acc: 95.65%\n",
      "Val Loss: 1.206237, Val Acc: 79.93%\n",
      "-------------\n",
      "Epoch: 83\n",
      "*** Least validation loss\n",
      "Train Loss: 1.070, Train Acc: 95.68%\n",
      "Val Loss: 1.204373, Val Acc: 79.93%\n",
      "-------------\n",
      "Epoch: 84\n",
      "Train Loss: 1.070, Train Acc: 95.70%\n",
      "Val Loss: 1.206806, Val Acc: 79.69%\n",
      "-------------\n",
      "Epoch: 85\n",
      "Train Loss: 1.070, Train Acc: 95.68%\n",
      "Val Loss: 1.208574, Val Acc: 79.45%\n",
      "-------------\n",
      "Epoch: 86\n",
      "Train Loss: 1.069, Train Acc: 95.73%\n",
      "Val Loss: 1.208161, Val Acc: 79.51%\n",
      "-------------\n",
      "Epoch: 87\n",
      "Train Loss: 1.069, Train Acc: 95.73%\n",
      "Val Loss: 1.207864, Val Acc: 79.51%\n",
      "-------------\n",
      "Epoch: 88\n",
      "Train Loss: 1.069, Train Acc: 95.73%\n",
      "Val Loss: 1.208666, Val Acc: 79.51%\n",
      "-------------\n",
      "Epoch: 89\n",
      "Train Loss: 1.069, Train Acc: 95.73%\n",
      "Val Loss: 1.209848, Val Acc: 79.33%\n",
      "-------------\n",
      "Epoch: 90\n",
      "Train Loss: 1.069, Train Acc: 95.73%\n",
      "Val Loss: 1.210285, Val Acc: 79.21%\n",
      "-------------\n",
      "Epoch: 91\n",
      "Train Loss: 1.069, Train Acc: 95.76%\n",
      "Val Loss: 1.210130, Val Acc: 79.39%\n",
      "-------------\n",
      "Epoch: 92\n",
      "Train Loss: 1.069, Train Acc: 95.76%\n",
      "Val Loss: 1.210326, Val Acc: 79.27%\n",
      "-------------\n",
      "Epoch: 93\n",
      "Train Loss: 1.069, Train Acc: 95.76%\n",
      "Val Loss: 1.212182, Val Acc: 79.09%\n",
      "-------------\n",
      "Epoch: 94\n",
      "Train Loss: 1.069, Train Acc: 95.73%\n",
      "Val Loss: 1.213687, Val Acc: 79.09%\n",
      "-------------\n",
      "Epoch: 95\n",
      "Train Loss: 1.069, Train Acc: 95.76%\n",
      "Val Loss: 1.216848, Val Acc: 78.55%\n",
      "-------------\n",
      "Epoch: 96\n",
      "Train Loss: 1.069, Train Acc: 95.76%\n",
      "Val Loss: 1.217956, Val Acc: 78.49%\n",
      "-------------\n",
      "Epoch: 97\n",
      "Train Loss: 1.069, Train Acc: 95.73%\n",
      "Val Loss: 1.219016, Val Acc: 78.31%\n",
      "-------------\n",
      "Epoch: 98\n",
      "Train Loss: 1.069, Train Acc: 95.73%\n",
      "Val Loss: 1.216528, Val Acc: 78.73%\n",
      "-------------\n",
      "Epoch: 99\n",
      "Train Loss: 1.069, Train Acc: 95.70%\n",
      "Val Loss: 1.208255, Val Acc: 79.51%\n",
      "-------------\n",
      "Epoch: 100\n",
      "Train Loss: 1.070, Train Acc: 95.60%\n",
      "Val Loss: 1.222208, Val Acc: 78.19%\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "num_bad_epochs = 0\n",
    "epoch = 0\n",
    "least_loss = float('inf')\n",
    "training_stats = pd.DataFrame(columns=['Epoch', 'Train_Loss', 'Train_Acc', 'Val_Loss', 'Val_Acc'])\n",
    "\n",
    "while(True):\n",
    "    train_loss, train_acc = train_model(model, optim, train_iter, epoch, batch_size)\n",
    "    val_loss, val_acc = eval_model(model, valid_iter) \n",
    "    print(f'Epoch: {epoch+1:02}')\n",
    "    if val_loss < least_loss:\n",
    "        least_loss = val_loss\n",
    "        num_bad_epochs = 0\n",
    "        print(\"*** Least validation loss\")\n",
    "        torch.save(model.state_dict(), \"IMDB_LSTM_100\")\n",
    "    else:\n",
    "        num_bad_epochs += 1\n",
    "#     print(f'Epoch: {epoch+1:2}, Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.2f}%')\n",
    "    print(f'Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.2f}%') \n",
    "    print(f'Val Loss: {val_loss:3f}, Val Acc: {val_acc:.2f}%')\n",
    "    print(\"-------------\")\n",
    "    \n",
    "    training_stats = training_stats.append(\n",
    "        pd.Series([epoch+1, train_loss, train_acc, val_loss, val_acc], index=training_stats.columns), \n",
    "        ignore_index=True)\n",
    "#     if num_bad_epochs >= 10:\n",
    "#         break\n",
    "        \n",
    "    epoch += 1\n",
    "    if epoch == 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_stats.to_csv(\"IMDB_LSTM_100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print model's state_dict\n",
    "# print(\"Model's state_dict:\")\n",
    "# for param_tensor in model.state_dict():\n",
    "#     print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "# # Print optimizer's state_dict\n",
    "# print(\"Optimizer's state_dict:\")\n",
    "# for var_name in optim.state_dict():\n",
    "#     print(var_name, \"\\t\", optim.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GANet(\n",
       "  (word_embeddings): Embedding(6958, 100)\n",
       "  (backbone): BackboneNet(\n",
       "    (backbone_lstm): LSTM(100, 100, num_layers=2, batch_first=True)\n",
       "  )\n",
       "  (mlp): MLP(\n",
       "    (ff_1): Linear(in_features=100, out_features=32, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (ff_2): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (FF): Linear(in_features=100, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = GANet(batch_size, num_classes, mlp_out_size, vocab_size, embedding_length, weights,biDirectional_backbone=False)\n",
    "loaded_model.load_state_dict(torch.load('IMDB_LSTM_100'))\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "vwMLkn7s7cnC",
    "outputId": "86182669-19b9-4b8d-b9a4-815acf8d240e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.102, Test Acc: 81.45\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = eval_model(loaded_model, test_iter)\n",
    "print(f'Test Loss: {test_loss:.3f}, Test Acc: {test_acc:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kj2OOxjKaAIm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'does', 'the', 'six-footed', 'musca', 'domestica', 'become', 'when', 'it', 'enters', 'a', 'house', '?']\n",
      "prediction = tensor([[1.0000e+00, 6.1565e-08, 2.7045e-08, 4.4736e-07, 1.5916e-07, 2.8326e-09]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(0)\n",
      "------------\n",
      "['who', 'killed', 'gandhi', '?']\n",
      "prediction = tensor([[1.8887e-07, 1.0000e+00, 7.4507e-07, 6.0203e-08, 4.8061e-08, 8.7848e-10]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(1)\n",
      "------------\n",
      "['what', 'does', 'target', 'heart', 'rate', 'mean', '?']\n",
      "prediction = tensor([[3.6494e-06, 5.9679e-04, 8.8522e-01, 1.0719e-01, 3.4901e-04, 6.6421e-03]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(2)\n",
      "------------\n",
      "['how', 'old', 'was', 'joan', 'of', 'arc', 'when', 'she', 'died', '?']\n",
      "prediction = tensor([[1.7911e-08, 1.7209e-09, 9.6585e-09, 1.0000e+00, 5.9320e-07, 4.8701e-07]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(3)\n",
      "------------\n",
      "['where', 'on', 'the', 'body', 'is', 'a', 'mortarboard', 'worn', '?']\n",
      "prediction = tensor([[2.7172e-07, 1.3203e-08, 3.3887e-09, 1.1822e-06, 1.0000e+00, 1.0838e-08]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(4)\n",
      "------------\n",
      "['what', 'does', 'i.v.', 'stand', 'for', '?']\n",
      "prediction = tensor([[1.4901e-05, 2.8383e-07, 2.4221e-06, 8.5505e-05, 6.2577e-06, 9.9989e-01]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(5)\n",
      "------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "def test_sentence(test_sen):\n",
    "    test_sen_list = TEXT.preprocess(test_sen)\n",
    "    print(test_sen_list)\n",
    "    test_sen = [[TEXT.vocab.stoi[x] for x in test_sen_list]]\n",
    "    # print(test_sen)\n",
    "\n",
    "    test_sen = np.asarray(test_sen)\n",
    "    test_sen = torch.LongTensor(test_sen)\n",
    "    test_tensor = Variable(test_sen, volatile=True)\n",
    "\n",
    "    # print(test_tensor)\n",
    "    loaded_model.eval()\n",
    "    prediction = loaded_model(test_tensor, is_train = False)\n",
    "    print(\"prediction =\", prediction)\n",
    "\n",
    "    out_class = torch.argmax(prediction)\n",
    "    return out_class\n",
    "\n",
    "\n",
    "''' Let us now predict the sentiment on a single sentence just for the testing purpose. '''\n",
    "test_sen1 = \"This is one of the best creation of Nolan. I can say, it's his magnum opus. Loved the soundtrack and especially those creative dialogues.\"\n",
    "test_sen2 = \"Ohh, such a ridiculous movie. Not gonna recommend it to anyone. Complete waste of time and money.\"\n",
    "\n",
    "print('------------')\n",
    "x = test_sentence(test_sen1)\n",
    "print(x)\n",
    "print('------------')\n",
    "x = test_sentence(test_sen2)\n",
    "print(x)\n",
    "print('------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise training and test loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Train_Loss</th>\n",
       "      <th>Train_Acc</th>\n",
       "      <th>Val_Loss</th>\n",
       "      <th>Val_Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.661547</td>\n",
       "      <td>34.244792</td>\n",
       "      <td>1.521777</td>\n",
       "      <td>49.399038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.472716</td>\n",
       "      <td>55.182292</td>\n",
       "      <td>1.443807</td>\n",
       "      <td>55.048077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.395580</td>\n",
       "      <td>62.812500</td>\n",
       "      <td>1.411567</td>\n",
       "      <td>58.653846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.344261</td>\n",
       "      <td>67.994792</td>\n",
       "      <td>1.332813</td>\n",
       "      <td>67.067308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.245297</td>\n",
       "      <td>77.994792</td>\n",
       "      <td>1.308926</td>\n",
       "      <td>69.411058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.0</td>\n",
       "      <td>1.068933</td>\n",
       "      <td>95.755208</td>\n",
       "      <td>1.217956</td>\n",
       "      <td>78.485577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.0</td>\n",
       "      <td>1.069193</td>\n",
       "      <td>95.729167</td>\n",
       "      <td>1.219016</td>\n",
       "      <td>78.305288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.0</td>\n",
       "      <td>1.069196</td>\n",
       "      <td>95.729167</td>\n",
       "      <td>1.216528</td>\n",
       "      <td>78.725962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.0</td>\n",
       "      <td>1.069408</td>\n",
       "      <td>95.703125</td>\n",
       "      <td>1.208255</td>\n",
       "      <td>79.507212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1.070467</td>\n",
       "      <td>95.598958</td>\n",
       "      <td>1.222208</td>\n",
       "      <td>78.185096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Epoch  Train_Loss  Train_Acc  Val_Loss    Val_Acc\n",
       "0     1.0    1.661547  34.244792  1.521777  49.399038\n",
       "1     2.0    1.472716  55.182292  1.443807  55.048077\n",
       "2     3.0    1.395580  62.812500  1.411567  58.653846\n",
       "3     4.0    1.344261  67.994792  1.332813  67.067308\n",
       "4     5.0    1.245297  77.994792  1.308926  69.411058\n",
       "..    ...         ...        ...       ...        ...\n",
       "95   96.0    1.068933  95.755208  1.217956  78.485577\n",
       "96   97.0    1.069193  95.729167  1.219016  78.305288\n",
       "97   98.0    1.069196  95.729167  1.216528  78.725962\n",
       "98   99.0    1.069408  95.703125  1.208255  79.507212\n",
       "99  100.0    1.070467  95.598958  1.222208  78.185096\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(training_stats['Train_Loss'], label=\"Train\")\n",
    "plt.plot(training_stats['Val_Loss'], label=\"Validation\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXxU9b3/8dd3su8hCSEbgbAo+xpRFBRErYiKWrRSrbjSerVaq7fX2v5subW92mvVetvS4lbaWqlVEfdKEQVrRcMOCasEyB6ybzOTmfn+/vhOSIAEJuvkTD7PxyOPzJw5M/OdmeQ9n/mc7zmjtNYIIYSwHpu/ByCEEKJrJMCFEMKiJMCFEMKiJMCFEMKiJMCFEMKigvvyzpKSkvTw4cP78i6FEMLyNm/efExrPfjk5X0a4MOHDycnJ6cv71IIISxPKXW4veXSQhFCCIuSABdCCIuSABdCCIuSABdCCIuSABdCCIuSABdCCIuSABdCCIvq03ngQggBoLWmwemm3u7C6fLgdLtxuDzmtMuD09162qMhJEgRGmzDphQNDhd1DhdNTnen77PZrXG6PThcHujgUNo2myIsOIjQYBta6+Nj8Xha11fKjCcs2EawTaGU8i6H0CAbocE2IkODSI4NJzUunMHRYQQH9Xy9LAEuhOgWh8tNWa2Dklo7xTV2SmqaKKlx4NGa0GAboUE2apqaKam1U1Jjp7zOQWWjE6fL49dxezP3FB19RULb9Tv7NQo2Be/ffyFnp8R07opnIAEuRDu01rg8mmZ3axXYsrzR6aaywUllg5OapmbqHC7q7S4crvYrQo9H4/Dejsvd+p/v8miqvLdTa28mKTqMId6KLSXO/E6Ni2BkchRhwUEdjrOk1o5HQ2JUKOEhQdib3Rw61sD+snrKau3Ue8dX2eikpMaEqEdrJmXEMzUznnOzEhmXFtvhc+F0efhnXilflddzuKKRgqomau3N1Dtc1NldVDY4T7lOZGgQwTZ1vHqNCQ8hNS6cIbHhjEmJISE6lMSoUKLDQkzIe4M+zHs6pM1pm1I0e6tmj9ZEhwUTHRZMZGjQ8crXVy2VfGiQrcPruj36ePWPwowjyIbN1rq+x+OtzN0nvqYe3XrdBqeL0uNvanZS48M7NVZfSICLgORwuTlW7yQtLvyEf9RGp4svDlUSEmQjISqU2IgQDpbVs+1oNduPVlNUY6eywUFVQzNOd89ViKHBNsKCbAQHtX7ctinFoMgQBkWFkh4fQUWDk4MHj1HqDeTj1w2yMT49lskZ8YSF2Ki3u6i1uzhS2cjBsnrqHa7j60aEBOFwuU+4PphAjY8IITU+grFpsbjdmi/zK3lrexEA0zLjuX1WFl8bn0JIm4/6Xxyq5JHVOzlQVg/A4Jgwhg6KICU2nOhwE6TJMebNZkhcOGneN5+Y8JAee+76WpBNEREaRERo+2+aYNos4bYgwkM6XgdgfFpcTw/vBBLgwnJyi2rZsL+cuIgQEqJCCQu2cbSqiSMVDeRXNHKgrJ7DFQ14tAmcWaOSmJgex6ZDFXyyrxx786nBrBSMGhxNZkIkE9JiSYgOJSo0+Hi1FtSm+ooICSIhKpSE6FDiI0KICQ8hOiyYsGBbhx/LO1MputwejtU7Ka5porC6iZ2FNWw9Us3fvjyKR2tiwoOJCgsmY1AEi6ZnMDI5mhCbosJbzUeFBjFqSAyjk6NJi48gOiz4hPG3VVJj5/1dxfzxs3zu/etWEqNCGZcWy8jB0dTam3ljSyHp8RE8d0s2F4xKJDJUIqM/UX35nZjZ2dlaDmYluqqmqZmnPtzLnz8/fEqFCabKHZYQyajkaEYnR5MUE0ZOfhWfHjhGZYOT5Jgw5k9I4ZJxQwi22ahqdFLd2MywxEgmZsQR28+rRq11p1sGvnJ7NOv3lPHermIOlNVzoKweh8vDnbOyuP+S0RLcfqaU2qy1zj5luQS46CyPR3OkspHdRbXkFtewu6iW/aXmo7zT5aHZ7SHIZnqNUaHB/PCKMSyckt6t+3x3RzGPrtlFVaOTm88bxr0Xj8Ll1lQ2OLE3u8kYFElyTNgJfcq24y2sbiI9PqLdy8WpPB6Nw+U5bRtB9J2OAlzeVsUp6uzNFNfYGTk4+vhH7zp7M29uLeTtHcXkFtUe77sG2xSjkqOZkZVAbHjw8Q1Qbm8AbD5cxQ9e28FZQ2IYm9rxhrKOOFxufvFuHiv/fZjJQ+NZefsMJqS39hXT4iPOeBs2m2JoQmSn73sgs3n7wKJ/kwAXOF0e9pfV8cWhStbllbHpUAXNbtNrPWd4AoMiQ3l/VzGNTjdjUmK4dmo649NiGZ8Wx+gh0afdkHOs3sEVv97IPS9v4a3vziI6rOM/ueKaJn72Ti6HjjUyNjWGcamxvL29iO0FNdw5K4v/mj/mhA1sQgx00kIZoEpr7fz534f5aE8Z+8vqaPZOhRo5OIpLxg5hVHI0W45Us+lQBcXVdq6clMrN5w1jUkZcp/uwn39VwTef+5yrJqfxzDemnHJ9rTWrvjzKL97No9njIXtYAntK6jhW7yAmLJj/vX4Sl09I7bHHLoTVSAtFUN3oZOvRalZvKeS9ncW4tea8rERun5XF+LQ4pmTEk5nY2mq4Pnso0P2NZ+eNSOSBS87iV2v34dFwxYQUZp81mKoGJ+/vKubt7cXsLKxh5ohEHv/6RIYlRgFQVmsnLCSIuIj+vXFRCH+RAO+nau3N7CqsITEqjMyEyE71Iz0eTUWDk/1ldeQW1bK7qJbtBdV8Vd4AQHRYMLfMHM6t5w8/IbA70hMzH+6ZO4qKBiertxby9vYigm0Kl3cqyYT0WJ74+kSunz70hI2MybE9v+ODEIFEWij9RK29mR1Ha/gyv5JPDxxj29Fq3G3myg2OCWNwdBiJ0aEkRYcxb2wyl49POX58hZz8Sv6w4SvyimsprbUfb4kApMSGMyE9lqmZg5iaGc+UofF+mxbmcpsNmx/vK2dQZAiXj0/16U1EiIFMphH2Q1prXt9SyIoNB9lfVo/WZoeSSelxzB49mOzhg6hpauZoZSNHKhupqHdS0eCksLqJ8joHaXHh3HDOUL44VMlnBytIjApl1ugkUuMiSI0LJyspinFpsSRFh/n7oQohukF64P3MwfJ6frR6J59/VcmkjDi+f8lZTMmMZ1JG/Bl7vi07Xbz4r0M888/9DI4J48cLxvLNczNlhwshBhD5b+8jDpebLw5VsvVINVuPVPGvAxWEh9j4xbUTufGcoZ3awSTIprhk3BAuGTeE4pomBkWGnvGYDEKIwCMB3gfW7y1j2Vu7ya9oPH7MjRtnDOXei0eRHNO9DXWpcWfekUUIEZh8CnCl1P3AXYACntNaP6OUSgD+BgwH8oEbtNZVvTROSyqsbmLZW7v5MLeUEUlR/P7maZw/KqnfH3NDCGENZwxwpdQETHjPAJzAB0qpd4ClwDqt9eNKqYeBh4H/6s3BWoXWmldzjvKzd/JwezQ/uPxs7piV1eExnYUQoit8qcDHApu01o0ASqlPgOuAhcAc7zorgY+RAKegqpFH1+zmoz1lnJuVwJPXT5bjcAgheoUvAb4L+LlSKhFoAq4AcoAhWuti7zolwJD2rqyUWoqp1snMzOz2gPujmsZm3t9VzJvbCtl0qJLQIBuPXjmOW88fLke/E0L0mjMGuNY6Tyn1BPAh0ABsA9wnraOVUu1OKNdarwBWgJkH3u0R9xPVjU4+2FXCe7tK+OzAMVwezYikKL437yyum5YuVbcQotf5tBFTa/0C8AKAUuoXQAFQqpRK1VoXK6VSgbLeG2b/sq+0jpuf30RZnYPMhEjunD2CBRNTmZAe22sH3BdCiJP5OgslWWtdppTKxPS/zwOygCXA497fa3ptlP3IzoIabnlxEyFBNl6/eybTMgdJaAsh/MLXeeCve3vgzcA9WutqpdTjwKtKqTuAw8ANvTXI/iInv5LbXvqS2IgQXr7zXIYnRfl7SEKIAczXFsrsdpZVAPN6fET91Ed7SvmPl7eQFhfBX+4816dvghFCiN4kX2/ig1e/PMpdf9rM6OQY/vbtmRLeQoh+QXalP4PlHx/kiQ/2MHt0Er+/eTpRp/lKMCGE6EuSRqexv7SOJz7Yw4JJqTx9wxRCg+UDixCi/5BEOo3lHx8kIiSIny2cIOEthOh3JJU6cLSykTXbi/jmuZkkRIX6ezhCCHEKCfAO/GHDQWwK7po9wt9DEUKIdkmAt6Os1s6rOQUsmp5BSpx8sa4Qon+SAG/HC58ewuX28O0LR/p7KEII0SGZheLV7PawYV85a7YV8cGuEq6clCZ7Wgoh+jUJcGDTVxXc+8pWyuscDIoM4frsDB649Cx/D0sIIU5rwAf433OO8sjqnWQmRPL4dROZPXqwTBkUQljCgA1wrTW//Mdeln98kFmjkvjtTdOIi5DvqhRCWMeADfD3dpaw/OODLJ6RyX8vHE9IkFTdQghrGZAB7vZonlq7l7OGRPPYNRMIkq89E0JY0IAsO9/cWsjB8ga+f+lZEt5CCMsacAHudHl4Zt0+JqTH8rXxKf4ejhBCdNmAC/C/bz7K0comHrzsbPkqNCGEpQ2oALc3u/m/dQeYPmwQc84a7O/hCCFEtwyoAF+x4StKau08JNW3ECIADJgAP1zRwG/WH2DBpFRmjkz093CEEKLbBkSAa615dM1uQoNsPHrlOH8PRwghesSACPAPdpXwyb5yHrj0LIbEyuFhhRCBIeADvN7hYtnbuYxLjWXJzGH+Ho4QQvQYnwJcKfWAUmq3UmqXUuoVpVS4UipLKbVJKXVAKfU3pVS//N6x13KOUlJr52fXjCdYdpcXQgSQMyaaUioduA/I1lpPAIKAG4EngKe11qOAKuCO3hxoV729o5gxKTFMH5bg76EIIUSP8vVYKMFAhFKqGYgEioGLgW96L18J/BRY3tMD7I6CqkY2H67iP792tr+HIoToiNawZSXkf9q6LCIBhp0Pw2dBVJL/xtbPnTHAtdaFSqkngSNAE/AhsBmo1lq7vKsVAOntXV8ptRRYCpCZmdkTY/bZuzuKAbhqUlqf3q8Qwke1RbDmHjj4EcSmQ3CYWV5XCl/8wZxOHmeCfPgsSJkIzkaw14Czvv3btAVB0lkQNxT8tb9Hsx2qDkHy2F69mzMGuFJqELAQyAKqgb8Dl/t6B1rrFcAKgOzsbN21YXbNOzuKmTw0nszEyL68WyH6N62hrhjCYiA0GpqqYN8HkPcONJTBLWsgtJtfJ1i2B+LSzX20x+WA7atg7aPgdsKCpyD79tbAdTdD0TbI32h+tv4FvljRuTGEx5vAT8iC+EyISYPqI1CyE8pyzWOMzzQ/SWdB6mTzZhHazbyoKYRV34TibfDNV+Gsr3Xv9k7DlxbKJcAhrXU5gFLqDeACIF4pFeytwjOAwl4bZRccOtbAzsIafrygd98BhTiBxwObX4RDGyHjnNaq0RbUuk7ZHvj8d3BwPWSeC2OuhFGXgLKZytLT3HvVo73WhEv+RnNeeTeDaQ9EJkHjMdj7Pkxc1PX7KNkFf7gQ0qbCre9ASETrZQ3H4MsX4MvnzZtFxgy49veQeNIXiAeFwNBzzM/s73sDfSuU7zVvChHx5s2nvefI5YCyPCjZAaW7Ye8H5r7MA4ak0SasXQ6oOgyHNrRW88oGoW3edNKmwGU/M+v74sgm+NvN0NwECSPgzbvh7s8gpncOnOdLgB8BzlNKRWJaKPOAHGA9sAhYBSwB1vTKCLvone1FACyYlOrnkVjc/n+aymfSDTBuofnH6q8KcuCjn4EtGMLjTB81eSykTIIh485cVWp9+tAs3wt73oWagtZlMakw5gpTudUWwZr/gK8+hqhkyH3TrBMSCfHDTKXnajKBERwOWRfBgXWw8++n3te0W0xV2tHzXZVv2g75n8LRL8xtXfk0BHsngznq4bXboaEcLl0GWRdCYyX85etQvB3mPGIqTXsN2EJg9KUmpJ6eALveOH2Au5xQW2Cq2cZKGH0ZhEWbyzweePf7JrQLc2DNvfD1583zemgjvHoLNHmvc95/wIg5vr1RBYXA0BnmxxfDzj/xvLPRfOqISTn170BrqDkKxTtMdW6v8T6WZvNc/OEimHITnLsUIhPN39bJbx61xeb/5LP/g/ihsORtc/kfLoLV34abV4Ot52fBKa3P3NVQSi0DvgG4gK3AnZie9yogwbvsZq2143S3k52drXNycro7Zp9c9vQnxEeE8up3ZvbJ/QWkXW/AG3eBCgK3w/QoJy82AWmvAY8Lpt8KKRNar3P4M/j4f8w/eXic+YOf/X1T9fSmqsPw3MWmgorLMONrKAdHrbncFgILfgXTl7Rex1EHHz9u/mmrj5hgjk42gZ8ywYSQvca0GA7/Gyr2m+tFJgIK0NBYYZYNyjLB5G6Gr/0cpt9mAiP/X1C0xdx+9WFTmU1ebC6PSgS3C45+btYLDoPwWCjfB5uWm6r8+pWt4ag1HPoEPl9uWh4A0SlmrAf+aULxhj+Byw4v32ACNDoF6org7AWmJ1txEG5YCWfPb/95/MePTBA9tN9UuSfb+jK89xA0N7YuG3ou3Py6qYy3/Bneuheu/o2petf9t3mziEyADx42Ven1f4Qh47v4QvexpmrY+CR8/nsT6C1CY8zznjLRrLP7DfC4Yfw15o030jvrbfMf4e374dL/hgvu7/IwlFKbtdbZpyz3JcB7Sl8F+N6SOr72zAZ+tnA835o5vNfvLyBt+ZP5wxt6LixeBUc3wb9/awIEICzWhJXbAVNvhpn3mupj658hNgMSR5jwO3bAVL93rO29DUqOOnjhMtN7vGtd65tFS2VVshO+eA6+Wg+X/RzOvxcqD8Eri+HYPkifZqrj2DSz8axkh1muPaZSDos1j2HMlXD2Faa326KuxLQc9rxj3ugu/59T2wFdkfMSvPugud+h55k3gGN7TeUdmQTn3AkTrzf3pZRZ/50HYNgF3ud9L3z9BVNZf/472PiUeT4WvwIjLur4fgs3mzfCq38D077VutztgrX/z9zW8Nkw+UbzqaKmwAR2+nS47jlYMcf0k29734xr9XdgxypzG6O/Bl9/zryxW031ESjcYp5be415My7ZBaW7AGWeqxlLTb+9La3Np46978Fd6yF1UpfufkAF+Ev/OsSyt3P5/IfzSImz6K7zLqf540iZBEEndbqaqkzQ2GtMhZkwwvy0BGRtMez/BwSFmh5sfAezf1wOE1Jte5QuJ3zyOGz8FYycB9/4y4kbdZwNJtRsQWYcn/zSVGwelwmwmffAnIdbP6Zu+RO89V1TSY6/pv1xHNoIeW+ZKrr6iHm8KZPMT3icCeHqwyZEhow3VU/iSHN/aBN0+9eaKnDk3I6fzzfuhNw1MPVbJnC1NtXoiDmnrt9sN79D/Pj3s+9D8wkI7d3YNsxUzhMWtT+una/BG0tNJX/jyzDy4tbLGipM1Rw/9PT3qTU8OxUGDYdbvC0ge60Joa/Ww7nfMW+Cbf8mc9fA328z9+tywHc2tlbYLofpAyeOgov+68RtAYHA4wHtPn1rsanKfGqa9f0u/z0NqAB/4oM9PL/xK/Y9Nt96h41tqICcF+HL56C+1FQ2166ApFEmVDb+Cj59+sSPc2C2sA+baUKw8KTnOH6Y6dGGx5kfe42pSo/thaAwmPJNOO9uU1G/cZepQKfebD4KtkzrOp1jB0wfd8yCUysMjxuWX2A+1t/zRWuPtkVdiQkMZTNtiPhMs27JDtMCaRGdYtapK2p/DAt+ZarS03G7zKeKbX+BwWNh8V/NG19/5vF0rndasNm8IQ/pxkHbPnrM/J09uNfM5Pjr9eZN9qpnTG++PbvfND33879reu6iRw2oAH/w1e38++AxPvvhvO7fWFO1+QjdCxsgABNwR78wG6PyN5it2G6H6X+OmAMbnjRVzPn3mp505UGYeIOpxMLjTKVbuttc/8jnEDPEfNQfs8BU1/mfmo1m1YdbP/4FR5igTZloqvVdr5nwtgWbHuxVv4axV/XcY9z3oQmB+b+Ec7994mVv32/6qvd+cWqY1pWYjXFxGa2VS0MFlO40b1Qt4tLN8+ULjwcOroPM8zqe4jbQleXB784zr1fhFtMCWfg7mHrT6a/XcMxsH7Ba0WQBAyrAb3nxC2oanay5d1b3bqimAJafD5nnm4+kbT/+FeSYWQDV3o/9Q8+FuT/y/Y/32H7Y9rKZC1tXDCizUSTrIvMRP3mMWa+22LujwzpToV751IkfjXtCXamp+hsr4KIfmA15PUlr+NPVpmd4/7bWHmjZHlg+0/QO5z/Rs/cpuud355uNns2N5u/6oh/4e0QDWkcB7uuu9JZSVmsnY1A3J+NrDe8+ZHq++96Hf/4ELnvMXNbSa9Ru89E+MgE2/K+ZYXDZYybE3S7Y8EuzgSsstnWLfs1RE/hNVaaHO+oSM2thxNzWLddtxaaa3u6Rf5t5tW371T0lZgjM/WHP324LpcxW+BVzTK/02t+bN4l//tRMx7pQwqHfmXCdmZI5bQlc+J/+Ho3oQEAG+LF6B1MzB3XvRnLfNMF92WMmcD/7P7N13eNu3dp/48smmLWG9/4T/v0bc37KTfDaHXDkM1O9o83sAY/L7KCRng2Dzzbzqn2Z4K/UqfNarSZtqulTf/CI+Xh+zp3m+Z33EzOdTvQvM+8xGzLHXSMtkX4s4ALc5fZQ0eAkOcaHjW8daaqC934AqVPg3LvNsooD8Pb3TNU9+mtm9kJLNayU6Rc6as0GoH89a8L62hUw+Rvdf1CB4pw7YdgsWL0UPnnCzCs/725/j0q0JySie3tjij4RcAFe0eBEaxjcnQD/8P+ZfvDNr7dOl1r0Evz5WlM5X/XsqbMpbDazocfjMmF/3XNmXXGi5DFwxz8h54XeawkJMUAEXICX1ZqdQbtcge96w+yMcsH9J06Ji4iHpetPf92gYFj0YtfudyAJDpXKW4geEHBfUVNeb3bA6FIFXrrbzPjImAFzf9zDIxNCiJ4VcAHeUoF3OsCbqmDVTWZu8A1/OrVFIoQQ/UzAtVDK67oQ4B4PvH6Xmfd96ztm6p4QQvRzARfgZXUO4iJCCAvuxDEXPv8dHFgLVzxp9tATQggLCLgWSnmdo3MbMMvyzCEvz77izMfSEEKIfiTgAryszu57+8TlNAdvCosxUwNlhwUhhIUEXICX13eiAv/EezD/q5+F6MG9OzAhhOhhARXgWmvKah2+VeB5b5vDsk692Ry5TwghLCagArzO4cLh8pAcc4aDpue9A3+/1RyT5PLH+2RsQgjR0wJqFkq7c8ALt5g+91Dvt3+77OZ82tTW7/ETQggLCqgAb5kDfkIPPOdFqD5qvt1l28tmWXq2Ce/wWD+MUgghekZABXhZ3Um70bucptc9biFc8zvz7TRFW8x0QSt+saoQQrQRUAHeWoF7e+CHPgF7tTk4fVCI+cLbjr70VgghLCagNmKW1zkIDbYRG+F9X9r1BoTF9fxXkAkhRD9wxgBXSp2tlNrW5qdWKfU9pVSCUmqtUmq/93c3vwKn+8rrHAyODjPfRO9ywJ53zRRBX75ZXQghLOaMAa613qu1nqK1ngJMBxqB1cDDwDqt9Whgnfe8X5XVtZkDfmAdOGpM+0QIIQJQZ1so84CDWuvDwEJgpXf5SuCanhxYV5xwHJTdqyE8HkbM8eeQhBCi13Q2wG8EXvGeHqK1LvaeLgGGtHcFpdRSpVSOUiqnvLy8i8P0TXm9twJvboK978HYq8zGSyGECEA+B7hSKhS4Gvj7yZdprTWg27ue1nqF1jpba509eHDvHW/E6fJQ2eA0Ab7/Q3DWS/tECBHQOlOBzwe2aK1LvedLlVKpAN7fZT09uM6oaGgzhXDzSohJheEX+nNIQgjRqzoT4ItpbZ8AvAUs8Z5eAqzpqUF1Rctu9JmqFA6ug2lLWr9RXgghApBPAa6UigIuBd5os/hx4FKl1H7gEu95v2nZieeso6+BCoLpS85wDSGEsDafSlStdQOQeNKyCsyslH6hrM5BKM0kHngVzp4PsWn+HpIQQvSqgNkTs7imiSuCviCoqRKyb/f3cIQQotcFTIDnFddxe/h6GJQFI+R4J0KIwBcwAW4v3Mkkdy5k3wa2gHlYQgjRoYBIuprGZqY2fIpGwZSb/D0cIYToEwER4HkltWSoYzgjBkNUkr+HI4QQfSIwAry4llRVgS0u3d9DEUKIPhMQAZ5bVEtmUAXBg4b6eyhCCNFnAiLA84prSFEVqLgMfw9FCCH6jOUD3OX2UFpWSrh2QKy0UIQQA4flA/yrYw0kub2HqZUeuBBiALF8gOcWmQ2YAMRKC0UIMXBYPsDzimsZGlRpzkgFLoQYQCwf4LnFtYyLqgNbMES3+6VAQggRkCwf4HnFtYwKq4GYNLAF+Xs4QgjRZywd4GV1do7VO0lTFdI+EUIMOJYO8LziOgAGucplCqEQYsCxeIDXovAQ1lQiFbgQYsCxdIAfLKvn7Gg7yu2UKYRCiAHH0gFeUNXEpJh6c0YqcCHEAGPtAK9u5KyIWnNGeuBCiAHGsgHucnsorraTFVJlFsiBrIQQA4xlA7y0zoHLo0mzVUJwOEQm+ntIQgjRpywb4AWVjQDmQFaxaaCUn0ckhBB9y6cAV0rFK6VeU0rtUUrlKaVmKqUSlFJrlVL7vb8H9fZg2yqoagIgxlkq7RMhxIDkawX+a+ADrfUYYDKQBzwMrNNajwbWec/3mZYAD2solimEQogB6YwBrpSKAy4EXgDQWju11tXAQmCld7WVwDW9Ncj2FFQ1khYTjKqXnXiEEAOTLxV4FlAOvKSU2qqUel4pFQUM0VoXe9cpAdo9FKBSaqlSKkcplVNeXt4zo8ZU4BPi7KA9MoVQCDEg+RLgwcA0YLnWeirQwEntEq21BnR7V9Zar9BaZ2utswcPHtzd8R5XUN3I2EjvHHDpgQshBiBfArwAKNBab/Kefw0T6KVKqVQA7++y3hniqVrmgI8K884BlwpcCDEAnTHAtdYlwFGl1NneRfOAXOAtYIl32RJgTa+MsB0ltXZcHk1GUMtOPBLgQoiBJ9jH9b4LvKyUCgW+Am7DhP+rSqk7gMPADb0zxFO1zEBJcRVCeJz5EUKIAcanAKwNCZwAAA/lSURBVNdabwOy27loXs8OxzctAZ5Uvgkyz/fHEIQQwu8suSdmQVUjGaqckJp8GDHHz6MRQgj/sGiANzE/cq85M2KOP4cihBB+Y9EAb+Si4N0QnQKDzz7zFYQQIgBZMsALKxuY7Npuqm85iJUQYoCyXIC73B5i6/YT466W9okQYkCzXICX1NqZyU5zZsRF/h2MEEL4keUCvKCqiVm2XTTGjjLHARdCiAHKcgFeWFHDDNseXMNm+3soQgjhV77uidlveI58QaRy0DzGL/sQCSFEv2G5Cjy+5DPc2AgZeaG/hyKEEH5luQBPq8/lkG2YHP9ECDHgWS7AU52HOBqS5e9hCCGE31krwJuqSXAfoyRsuL9HIoQQfmetAC83xz8pjxjh54EIIYT/WSvAy3IBqIoa6eeBCCGE/1krwMv30Eg4jijZgUcIIawV4GV5HNTpRISF+nskQgjhd5YKcF2WR54ng6jQIH8PRQgh/M46Ad5YiWooY58ng4hQy+1AKoQQPc46AV6WB8A+nUFUmFTgQghhoQA3M1D2eTKIlApcCCEsFODle3CHxlBCgvTAhRACKwV42R6a4s8CFBES4EII4VuAK6XylVI7lVLblFI53mUJSqm1Sqn93t+Dem2UWkNZLnWxowCICpMWihBCdKYCn6u1nqK1zvaefxhYp7UeDazznu8dDeXQVEm1dw/MSKnAhRCiWy2UhcBK7+mVwDXdH04HvDNQKo4HuFTgQgjha4Br4EOl1Gal1FLvsiFa62Lv6RJgSHtXVEotVUrlKKVyysvLuzZKb4CXhJnDyMpGTCGE8P0r1WZprQuVUsnAWqXUnrYXaq21Ukq3d0Wt9QpgBUB2dna765xReR5EJFBJHFBCpPTAhRDCtwpca13o/V0GrAZmAKVKqVQA7++y3hokDccgeRyNzR4AIkKkAhdCiDMGuFIqSikV03IauAzYBbwFLPGutgRY01uD5MaX4VuraXS6CQ+xEWRTvXZXQghhFb70IoYAq5VSLev/VWv9gVLqS+BVpdQdwGHght4bJhAcSoPDRZRswBRCCMCHANdafwVMbmd5BTCvNwbVkSanm0g5DooQQgBW2hMTaHC6iAyRClwIIcBiAd4oFbgQQhxnqQCXHrgQQrSyVIA3Ot1yICshhPCyXIDLXphCCGFYLMBdshemEEJ4WSzApQIXQogWlglwj0d7e+BSgQshBFgowJua3YAciVAIIVpYJsAbnC4A6YELIYSXZQK8yWkq8Eg5EqEQQgAWCvAGh7eFIntiCiEEYKEAb2xpochGTCGEACwV4N4WimzEFEIIwFIBLhW4EEK0ZZkAlx64EEKcyDIBLhW4EEKcyDJpKD1wIfqP5uZmCgoKsNvt/h5KQAkPDycjI4OQkBCf1rdMgDd4A1y+kV4I/ysoKCAmJobhw4fj/b5c0U1aayoqKigoKCArK8un61inheJwERkahE2+kV4Iv7Pb7SQmJkp49yClFImJiZ36VGOdAG92S/tEiH5EwrvndfY5tU6AO1yyAVMIIdqwTIA3OKUCF0IYFRUVTJkyhSlTppCSkkJ6evrx806n06fbuO2229i7d28vj7R3+VzSKqWCgBygUGt9pVIqC1gFJAKbgW9prX175rqgyekmSo5EKIQAEhMT2bZtGwA//elPiY6O5qGHHjphHa01Wmtstvbr1JdeeqnXx9nbOpOI9wN5QKz3/BPA01rrVUqp3wN3AMt7eHzHNThdREuAC9HvLHt7N7lFtT16m+PSYvnJVeM7fb0DBw5w9dVXM3XqVLZu3cratWtZtmwZW7ZsoampiW984xs8+uijAMyaNYvf/OY3TJgwgaSkJL7zne/w/vvvExkZyZo1a0hOTu7Rx9QbfGqhKKUygAXA897zCrgYeM27ykrgmt4YYItGh7RQhBBntmfPHh544AFyc3NJT0/n8ccfJycnh+3bt7N27Vpyc3NPuU5NTQ0XXXQR27dvZ+bMmbz44ot+GHnn+VrSPgP8AIjxnk8EqrXWLu/5AiC9vSsqpZYCSwEyMzO7PNAGp4so2YgpRL/TlUq5N40cOZLs7Ozj51955RVeeOEFXC4XRUVF5ObmMm7cuBOuExERwfz58wGYPn06Gzdu7NMxd9UZK3Cl1JVAmdZ6c1fuQGu9QmudrbXOHjx4cFduAjA98AipwIUQZxAVFXX89P79+/n1r3/NRx99xI4dO7j88svbnWcdGhp6/HRQUBAul+uUdfojX1ooFwBXK6XyMRstLwZ+DcQrpVpK4gygsFdG6NXgdMlGTCFEp9TW1hITE0NsbCzFxcX84x//8PeQetQZA1xr/UOtdYbWejhwI/CR1vomYD2wyLvaEmBNbw3S7dHYmz3SAxdCdMq0adMYN24cY8aM4ZZbbuGCCy7w95B6lNJa+76yUnOAh7zTCEdgKvIEYCtws9bacbrrZ2dn65ycnE4Pst7hYsJP/sEjV4xh6YUjO319IUTPysvLY+zYsf4eRkBq77lVSm3WWmefvG6nehJa64+Bj72nvwJmdHmUndDokEPJCiHEySyxJ2bLkQjlyxyEEKKVNQJcKnAhhDiFJQK8qVm+zEEIIU5miQCXClwIIU5liQBvlB64EEKcwlIBHhkiFbgQAubOnXvKTjnPPPMMd999d4fXiY6OBqCoqIhFixa1u86cOXM401TnZ555hsbGxuPnr7jiCqqrq30deo+ySIB7WyhSgQshgMWLF7Nq1aoTlq1atYrFixef8bppaWm89tprZ1yvIycH+HvvvUd8fHyXb687LFHSNji8LRTpgQvR/7z/MJTs7NnbTJkI8x/v8OJFixbx4x//GKfTSWhoKPn5+RQVFTF16lTmzZtHVVUVzc3NPPbYYyxcuPCE6+bn53PllVeya9cumpqauO2229i+fTtjxoyhqanp+Hp33303X375JU1NTSxatIhly5bx7LPPUlRUxNy5c0lKSmL9+vUMHz6cnJwckpKSeOqpp44fyfDOO+/ke9/7Hvn5+cyfP59Zs2bx2WefkZ6ezpo1a4iIiOj202SZClwpCA+xxHCFEL0sISGBGTNm8P777wOm+r7hhhuIiIhg9erVbNmyhfXr1/Pggw9yur3Nly9fTmRkJHl5eSxbtozNm1uP2ffzn/+cnJwcduzYwSeffMKOHTu47777SEtLY/369axfv/6E29q8eTMvvfQSmzZt4vPPP+e5555j69atgDmo1j333MPu3buJj4/n9ddf75HnwRIlbaPTTWRIkHyJqhD90Wkq5d7U0kZZuHAhq1at4oUXXkBrzSOPPMKGDRuw2WwUFhZSWlpKSkpKu7exYcMG7rvvPgAmTZrEpEmTjl/26quvsmLFClwuF8XFxeTm5p5w+ck+/fRTrr322uNHQ7zuuuvYuHEjV199NVlZWUyZMgUwh6vNz8/vkefAEiVto9NFpByJUAjRxsKFC1m3bh1btmyhsbGR6dOn8/LLL1NeXs7mzZvZtm0bQ4YMaffwsWdy6NAhnnzySdatW8eOHTtYsGBBl26nRVhY2PHTPXm4WksEeIPDTZTsxCOEaCM6Opq5c+dy++23H994WVNTQ3JyMiEhIaxfv57Dhw+f9jYuvPBC/vrXvwKwa9cuduzYAZjD0EZFRREXF0dpaenxVg1ATEwMdXV1p9zW7NmzefPNN2lsbKShoYHVq1cze/bsnnq47bJEWdvodBMhGzCFECdZvHgx11577fEZKTfddBNXXXUVEydOJDs7mzFjxpz2+nfffTe33XYbY8eOZezYsUyfPh2AyZMnM3XqVMaMGcPQoUNPOAzt0qVLufzyy4/3wltMmzaNW2+9lRkzzDH+7rzzTqZOndpj7ZL2dOpwst3V1cPJ/nb9AersLh6ef/oXQwjRN+Rwsr2n1w4n6y/3zB3l7yEIIUS/Y4keuBBCiFNJgAshuqQv268DRWefUwlwIUSnhYeHU1FRISHeg7TWVFRUEB4e7vN1LNEDF0L0LxkZGRQUFFBeXu7voQSU8PBwMjIyfF5fAlwI0WkhISFkZWX5exgDnrRQhBDCoiTAhRDCoiTAhRDCovp0T0ylVDlw+oMTdCwJONaDw7GKgfi4B+JjhoH5uOUx+2aY1nrwyQv7NMC7QymV096upIFuID7ugfiYYWA+bnnM3SMtFCGEsCgJcCGEsCgrBfgKfw/ATwbi4x6IjxkG5uOWx9wNlumBCyGEOJGVKnAhhBBtSIALIYRFWSLAlVKXK6X2KqUOKKUe9vd4eoNSaqhSar1SKlcptVspdb93eYJSaq1Sar/39yB/j7WnKaWClFJblVLveM9nKaU2eV/vvymlQv09xp6mlIpXSr2mlNqjlMpTSs0M9NdaKfWA9297l1LqFaVUeCC+1kqpF5VSZUqpXW2WtfvaKuNZ7+PfoZSa1pn76vcBrpQKAn4LzAfGAYuVUuP8O6pe4QIe1FqPA84D7vE+zoeBdVrr0cA67/lAcz+Q1+b8E8DTWutRQBVwh19G1bt+DXygtR4DTMY8/oB9rZVS6cB9QLbWegIQBNxIYL7WfwQuP2lZR6/tfGC092cpsLwzd9TvAxyYARzQWn+ltXYCq4CFfh5Tj9NaF2utt3hP12H+odMxj3Wld7WVwDX+GWHvUEplAAuA573nFXAx8Jp3lUB8zHHAhcALAFprp9a6mgB/rTFHP41QSgUDkUAxAfhaa603AJUnLe7otV0I/EkbnwPxSqlUX+/LCgGeDhxtc77AuyxgKaWGA1OBTcAQrXWx96ISYIifhtVbngF+AHi85xOBaq21y3s+EF/vLKAceMnbOnpeKRVFAL/WWutC4EngCCa4a4DNBP5r3aKj17Zb+WaFAB9QlFLRwOvA97TWtW0v02bOZ8DM+1RKXQmUaa03+3ssfSwYmAYs11pPBRo4qV0SgK/1IEy1mQWkAVGc2mYYEHrytbVCgBcCQ9ucz/AuCzhKqRBMeL+stX7Du7i05SOV93eZv8bXCy4ArlZK5WNaYxdjesPx3o/ZEJivdwFQoLXe5D3/GibQA/m1vgQ4pLUu11o3A29gXv9Af61bdPTadivfrBDgXwKjvVurQzEbPt7y85h6nLf3+wKQp7V+qs1FbwFLvKeXAGv6emy9RWv9Q611htZ6OOZ1/UhrfROwHljkXS2gHjOA1roEOKqUOtu7aB6QSwC/1pjWyXlKqUjv33rLYw7o17qNjl7bt4BbvLNRzgNq2rRazkxr3e9/gCuAfcBB4Ef+Hk8vPcZZmI9VO4Bt3p8rMD3hdcB+4J9Agr/H2kuPfw7wjvf0COAL4ADwdyDM3+Prhcc7Bcjxvt5vAoMC/bUGlgF7gF3An4GwQHytgVcwff5mzKetOzp6bQGFmWV3ENiJmaXj833JrvRCCGFRVmihCCGEaIcEuBBCWJQEuBBCWJQEuBBCWJQEuBBCWJQEuBBCWJQEuBBCWNT/B4UBm3RLbRAOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_stats['Train_Acc'], label=\"Train\")\n",
    "plt.plot(training_stats['Val_Acc'], label=\"Validation\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GANet_Torch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
